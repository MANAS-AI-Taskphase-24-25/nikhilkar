{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Y1ucv8TYPpLA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import zipfile\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "class Network:\n",
        "    def __init__(self, input_dim, hidden_layers, output_dim, dropout_ratio=0.2):\n",
        "        self.num_stages = len(hidden_layers) + 1\n",
        "        self.weight_matrices = []\n",
        "        self.bias_vectors = []\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        layer_dimensions = [input_dim] + hidden_layers + [output_dim]\n",
        "\n",
        "        # Initialize weight matrices and bias vectors\n",
        "        for layer in range(self.num_stages):\n",
        "            self.weight_matrices.append(\n",
        "                np.random.randn(layer_dimensions[layer], layer_dimensions[layer + 1]) * np.sqrt(2 / layer_dimensions[layer])\n",
        "            )\n",
        "            self.bias_vectors.append(np.zeros((1, layer_dimensions[layer + 1])))\n",
        "\n",
        "    def activation_relu(self, matrix):\n",
        "        return np.maximum(0, matrix)\n",
        "\n",
        "    def relu_gradient(self, matrix):\n",
        "        return (matrix > 0).astype(float)\n",
        "\n",
        "    def activation_softmax(self, matrix):\n",
        "        exponential_values = np.exp(matrix - np.max(matrix, axis=1, keepdims=True))\n",
        "        return exponential_values / np.sum(exponential_values, axis=1, keepdims=True)\n",
        "\n",
        "    def dropout_masking(self, matrix):\n",
        "        mask = np.random.binomial(1, 1 - self.dropout_ratio, size=matrix.shape) / (1 - self.dropout_ratio)\n",
        "        return matrix * mask\n",
        "\n",
        "    def forward_pass(self, input_data, is_training=True):\n",
        "        # Flatten input if necessary\n",
        "        if len(input_data.shape) > 2:  # If images are not flattened\n",
        "            input_data = input_data.reshape(input_data.shape[0], -1)\n",
        "\n",
        "        self.layer_outputs = [input_data]  # Store inputs as the first activation\n",
        "        self.intermediate_z = []\n",
        "\n",
        "        for layer in range(self.num_stages - 1):\n",
        "            # Ensure dimensions are correct\n",
        "            z_calc = np.dot(self.layer_outputs[-1], self.weight_matrices[layer]) + self.bias_vectors[layer]\n",
        "            self.intermediate_z.append(z_calc)\n",
        "            activation_output = self.activation_relu(z_calc)\n",
        "\n",
        "            if is_training:\n",
        "                activation_output = self.dropout_masking(activation_output)  # Dropout if training\n",
        "            self.layer_outputs.append(activation_output)\n",
        "\n",
        "        z_final = np.dot(self.layer_outputs[-1], self.weight_matrices[-1]) + self.bias_vectors[-1]\n",
        "        self.intermediate_z.append(z_final)\n",
        "        self.layer_outputs.append(self.activation_softmax(z_final))\n",
        "\n",
        "        return self.layer_outputs[-1]\n",
        "\n",
        "    def backward_pass(self, input_data, true_labels, predicted_output):\n",
        "        sample_count = input_data.shape[0]\n",
        "        self.gradient_weights = []\n",
        "        self.gradient_biases = []\n",
        "\n",
        "        delta = predicted_output - true_labels\n",
        "        for layer in range(self.num_stages - 1, -1, -1):\n",
        "            gradient_w = np.dot(self.layer_outputs[layer].T, delta) / sample_count\n",
        "            gradient_b = np.sum(delta, axis=0, keepdims=True) / sample_count\n",
        "\n",
        "            self.gradient_weights.insert(0, gradient_w)\n",
        "            self.gradient_biases.insert(0, gradient_b)\n",
        "\n",
        "            if layer > 0:\n",
        "                delta_activation = np.dot(delta, self.weight_matrices[layer].T)\n",
        "                delta = delta_activation * self.relu_gradient(self.intermediate_z[layer - 1])\n",
        "\n",
        "    def parameter_update(self, learning_rate, l2_penalty):\n",
        "        for layer in range(self.num_stages):\n",
        "            self.weight_matrices[layer] -= learning_rate * (self.gradient_weights[layer] + l2_penalty * self.weight_matrices[layer])\n",
        "            self.bias_vectors[layer] -= learning_rate * self.gradient_biases[layer]\n",
        "\n",
        "\n",
        "def transform_image(image_data):\n",
        "    reshaped_image = image_data.reshape(28, 28)\n",
        "\n",
        "    # Apply random rotation\n",
        "    if np.random.rand() < 0.5:\n",
        "        rotation_angle = np.random.randint(-20, 20)\n",
        "        reshaped_image = cv2.warpAffine(\n",
        "            reshaped_image,\n",
        "            cv2.getRotationMatrix2D((14, 14), rotation_angle, 1.0),\n",
        "            (28, 28)\n",
        "        )\n",
        "\n",
        "    # Apply horizontal flipping\n",
        "    if np.random.rand() < 0.5:\n",
        "        reshaped_image = cv2.flip(reshaped_image, 1)\n",
        "\n",
        "    # Horizontal shifting\n",
        "    if np.random.rand() < 0.5:\n",
        "        horizontal_shift = np.random.randint(-5, 5)\n",
        "        reshaped_image = np.roll(reshaped_image, horizontal_shift, axis=1)\n",
        "\n",
        "    # Vertical shifting\n",
        "    if np.random.rand() < 0.5:\n",
        "        vertical_shift = np.random.randint(-5, 5)\n",
        "        reshaped_image = np.roll(reshaped_image, vertical_shift, axis=0)\n",
        "\n",
        "    return reshaped_image.flatten()\n",
        "\n",
        "def zip_content(archive_path):\n",
        "    picture_set = []\n",
        "    class_labels = []\n",
        "\n",
        "    with zipfile.ZipFile(archive_path, \"r\") as archive:\n",
        "        file_entries = archive.namelist()\n",
        "\n",
        "        for entry in file_entries:\n",
        "            directory_parts = entry.split('/')\n",
        "            if len(directory_parts) > 1 and directory_parts[-1].endswith('.png'):\n",
        "                category_name = directory_parts[-2]\n",
        "\n",
        "                image_matrix = cv2.imdecode(\n",
        "                    np.frombuffer(archive.read(entry), np.uint8), cv2.IMREAD_GRAYSCALE\n",
        "                )\n",
        "                if image_matrix is not None:\n",
        "                    image_matrix = cv2.resize(image_matrix, (28, 28))  # Resize to 28x28\n",
        "                    image_matrix = image_matrix / 255.0\n",
        "                    picture_set.append(image_matrix.flatten())\n",
        "                    class_labels.append(category_name)\n",
        "\n",
        "        picture_set = np.array(picture_set)\n",
        "\n",
        "        # Map text-based categories to numeric values\n",
        "        class_to_index = {category: idx for idx, category in enumerate(sorted(set(class_labels)))}\n",
        "        numeric_classes = np.array([class_to_index[cls] for cls in class_labels])\n",
        "\n",
        "        return picture_set, numeric_classes, class_to_index\n",
        "\n",
        "train_zip_path = 'Train (1).zip'\n",
        "train_images, train_labels, label_map = zip_content(train_zip_path)\n",
        "\n",
        "test_zip_path = 'Test (1).zip'\n",
        "test_images, test_labels, _ = zip_content(test_zip_path)\n",
        "\n",
        "def encode(labels, num_classes):\n",
        "    labels = labels.astype(int)\n",
        "    return np.eye(num_classes)[labels]\n",
        "\n",
        "num_classes = len(label_map)\n",
        "\n",
        "train_labels = encode(train_labels, num_classes)\n",
        "test_labels = encode(test_labels, num_classes)\n",
        "\n",
        "pixels = 784  # Update input size for 28x28 images\n",
        "layers = [30]\n",
        "output_size = num_classes\n",
        "alpha = 0.02\n",
        "iterations = 300\n",
        "batch_size = 32\n",
        "xlambda = 0.01\n",
        "rate = 0.8\n",
        "\n",
        "network = Network(pixels, layers, output_size)\n",
        "\n",
        "for epoch in range(iterations):\n",
        "    permutation = np.random.permutation(train_images.shape[0])\n",
        "    train_images = train_images[permutation]\n",
        "    train_labels = train_labels[permutation]\n",
        "\n",
        "    epoch_loss = 0\n",
        "    for i in range(0, train_images.shape[0], batch_size):\n",
        "        batch_X = train_images[i:i + batch_size]\n",
        "        batch_y = train_labels[i:i + batch_size]\n",
        "\n",
        "        batch_X = np.array([transform_image(img) for img in batch_X])\n",
        "\n",
        "        output = network.forward_pass(batch_X)\n",
        "        cross_entropy_loss = -np.mean(np.sum(batch_y * np.log(output + 1e-15), axis=1))\n",
        "        l2_loss = (xlambda / 2) * sum(np.sum(np.square(w)) for w in network.weight_matrices)\n",
        "        loss = cross_entropy_loss + l2_loss\n",
        "        epoch_loss += loss\n",
        "\n",
        "        network.backward_pass(batch_X, batch_y, output)\n",
        "        network.parameter_update(alpha, xlambda)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIYZduq_QByU",
        "outputId": "363711e0-217f-4462-c648-d2ca95ceb3be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 91.1000%\n",
            "Precision (Macro): 91.4322%\n",
            "Recall (Macro): 91.1000%\n",
            "F1-Score (Macro): 90.9983%\n",
            "Confusion Matrix:\n",
            "[[199   0   0   1   0]\n",
            " [  0 192   0   8   0]\n",
            " [  7   0 167   3  23]\n",
            " [  0  37   2 161   0]\n",
            " [  0   0   8   0 192]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(predictions, true_labels):\n",
        "    # Get predicted classes by taking the index of the max probability\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "    # Get true class labels by taking the index of the max value in the one-hot encoded vector\n",
        "    true_classes = np.argmax(true_labels, axis=1)\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "\n",
        "    # Precision, Recall, and F1-Score (per class, macro average)\n",
        "    precision = precision_score(true_classes, predicted_classes, average='macro')\n",
        "    recall = recall_score(true_classes, predicted_classes, average='macro')\n",
        "    f1 = f1_score(true_classes, predicted_classes, average='macro')\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "    return accuracy, precision, recall, f1, conf_matrix\n",
        "\n",
        "# Calculate metrics after training\n",
        "predictions = network.forward_pass(test_images, is_training=False)\n",
        "accuracy, precision, recall, f1, conf_matrix = evaluate_model(predictions, test_labels)\n",
        "\n",
        "print(f\"Accuracy: {accuracy*100:.4f}%\")\n",
        "print(f\"Precision (Macro): {precision*100:.4f}%\")\n",
        "print(f\"Recall (Macro): {recall*100:.4f}%\")\n",
        "print(f\"F1-Score (Macro): {f1*100:.4f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
